{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comments Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "from nltk import Text\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.tokenize import sent_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPath = \"data/train.csv\"\n",
    "testPath = \"data/test.csv\"\n",
    "df_train = pd.read_csv(trainPath)\n",
    "df_test = pd.read_csv(testPath)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanning\n",
    "#### Fill NA\n",
    "#### Remove special character\n",
    "#### Romove stop words\n",
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>[aww, matches, background, colour, seemingly, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>[make, real, suggestions, improvement, wondere...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  [explanation, edits, made, username, hardcore,...      0   \n",
       "1  000103f0d9cfb60f  [aww, matches, background, colour, seemingly, ...      0   \n",
       "2  000113f07ec002fd  [hey, man, really, trying, edit, war, guy, con...      0   \n",
       "3  0001b41b1c6bb37e  [make, real, suggestions, improvement, wondere...      0   \n",
       "4  0001d958c54c6e35                [sir, hero, chance, remember, page]      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "\n",
    "df_train['comment_text']= df_train['comment_text'].apply(lambda comment: regexp_tokenize(comment, pattern='[a-zA-Z]+'))\n",
    "stopWords = set(stopwords.words('english'))\n",
    "df_train['comment_text'] = df_train['comment_text'].apply(lambda comment:[token.lower() for token in comment])\n",
    "df_train['comment_text'] = df_train['comment_text'].apply(lambda comment:[token for token in comment if token not in stopWords])\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>[expl, edit, mad, usernam, hardc, metallic, fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>[aww, match, background, colo, seem, stuck, th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>[hey, man, real, try, edit, war, guy, const, r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>[mak, real, suggest, improv, wond, sect, stat,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>[sir, hero, chant, rememb, pag]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  [expl, edit, mad, usernam, hardc, metallic, fa...      0   \n",
       "1  000103f0d9cfb60f  [aww, match, background, colo, seem, stuck, th...      0   \n",
       "2  000113f07ec002fd  [hey, man, real, try, edit, war, guy, const, r...      0   \n",
       "3  0001b41b1c6bb37e  [mak, real, suggest, improv, wond, sect, stat,...      0   \n",
       "4  0001d958c54c6e35                    [sir, hero, chant, rememb, pag]      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from nltk.stem import PorterStemmer\n",
    "# porter = PorterStemmer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lst = LancasterStemmer() # initiating LancasterStemmer\n",
    "df_train['comment_text'] = df_train['comment_text'].apply(lambda comment:[lst.stem(token) for token in comment])\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>expl edit mad usernam hardc metallic fan rever...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>aww match background colo seem stuck thank tal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man real try edit war guy const remov rele...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>mak real suggest improv wond sect stat lat sub...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>sir hero chant rememb pag</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  expl edit mad usernam hardc metallic fan rever...      0   \n",
       "1  000103f0d9cfb60f  aww match background colo seem stuck thank tal...      0   \n",
       "2  000113f07ec002fd  hey man real try edit war guy const remov rele...      0   \n",
       "3  0001b41b1c6bb37e  mak real suggest improv wond sect stat lat sub...      0   \n",
       "4  0001d958c54c6e35                          sir hero chant rememb pag      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['comment_text'] = df_train['comment_text'].apply(lambda comment: ' '.join(comment))\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['comment_text']= df_test['comment_text'].apply(lambda comment: regexp_tokenize(comment, pattern='[a-zA-Z]+'))\n",
    "df_test['comment_text'] = df_test['comment_text'].apply(lambda comment:[token.lower() for token in comment])\n",
    "stopWords = set(stopwords.words('english'))\n",
    "df_test['comment_text'] = df_test['comment_text'].apply(lambda comment:[token for token in comment if token not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>[yo, bitch, ja, rule, succesful, ever, whats, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>[rfc, title, fine, imo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>[sources, zawe, ashton, lapland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>[look, back, source, information, updated, cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>[anonymously, edit, articles]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  [yo, bitch, ja, rule, succesful, ever, whats, ...\n",
       "1  0000247867823ef7                            [rfc, title, fine, imo]\n",
       "2  00013b17ad220c46                   [sources, zawe, ashton, lapland]\n",
       "3  00017563c3f7919a  [look, back, source, information, updated, cor...\n",
       "4  00017695ad8997eb                      [anonymously, edit, articles]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>[yo, bitch, ja, rul, succes, ev, what, hat, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>[rfc, titl, fin, imo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>[sourc, zaw, ashton, lapland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>[look, back, sourc, inform, upd, correct, form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>[anonym, edit, artic]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  [yo, bitch, ja, rul, succes, ev, what, hat, sa...\n",
       "1  0000247867823ef7                              [rfc, titl, fin, imo]\n",
       "2  00013b17ad220c46                      [sourc, zaw, ashton, lapland]\n",
       "3  00017563c3f7919a  [look, back, sourc, inform, upd, correct, form...\n",
       "4  00017695ad8997eb                              [anonym, edit, artic]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['comment_text'] = df_test['comment_text'].apply(lambda comment:[lst.stem(token) for token in comment])\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>yo bitch ja rul succes ev what hat sad mofucka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>rfc titl fin imo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>sourc zaw ashton lapland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>look back sourc inform upd correct form guess ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>anonym edit artic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  yo bitch ja rul succes ev what hat sad mofucka...\n",
       "1  0000247867823ef7                                   rfc titl fin imo\n",
       "2  00013b17ad220c46                           sourc zaw ashton lapland\n",
       "3  00017563c3f7919a  look back sourc inform upd correct form guess ...\n",
       "4  00017695ad8997eb                                  anonym edit artic"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['comment_text'] = df_test['comment_text'].apply(lambda comment: ' '.join(comment))\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentences_train = df_train[\"comment_text\"].fillna(\"_na_\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = df_train[list_classes].values\n",
    "list_sentences_test = df_test[\"comment_text\"].fillna(\"_na_\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = df_train.comment_text\n",
    "y_train = df_train[list_classes]\n",
    "\n",
    "# X_train, X_validate, y_train, y_validate = train_test_split(\n",
    "#     df_data, df_label, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = df_test[\"comment_text\"].fillna(\"_na_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(X_train.values)\n",
    "# list_tokenized_validate = tokenizer.texts_to_sequences(X_validate.values)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 200)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 200\n",
    "feature_tokenizer_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "# feature_tokenizer_validate = pad_sequences(list_tokenized_validate, maxlen=maxlen)\n",
    "feature_tokenizer_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "print feature_tokenizer_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 3000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features = 3000)\n",
    "features_CountVectorizer_train = vectorizer.fit_transform(X_train)\n",
    "# features_CountVectorizer_validate = vectorizer.transform(X_validate)\n",
    "features_CountVectorizer_test = vectorizer.transform(X_test)\n",
    "feature_names_CountVectorizer = vectorizer.get_feature_names()\n",
    "print features_CountVectorizer_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Importance\n",
      "fuck        0.138571\n",
      "artic       0.047143\n",
      "us          0.034286\n",
      "would       0.031429\n",
      "on          0.022857\n",
      "suck        0.021429\n",
      "idiot       0.021429\n",
      "stupid      0.018571\n",
      "shit        0.017143\n",
      "gay         0.017143\n",
      "bullshit    0.015714\n",
      "crap        0.014286\n",
      "asshol      0.014286\n",
      "cunt        0.012857\n",
      "ass         0.012857\n",
      "bitch       0.012857\n",
      "also        0.012857\n",
      "faggot      0.012857\n",
      "jerk        0.011429\n",
      "dick        0.011429\n",
      "pathet      0.011429\n",
      "hel         0.011429\n",
      "fag         0.010000\n",
      "liar        0.010000\n",
      "act         0.010000\n",
      "hat         0.010000\n",
      "moron       0.010000\n",
      "see         0.008571\n",
      "retard      0.008571\n",
      "damn        0.008571\n",
      "...              ...\n",
      "fggt        0.000000\n",
      "fict        0.000000\n",
      "field       0.000000\n",
      "fif         0.000000\n",
      "fig         0.000000\n",
      "fight       0.000000\n",
      "fil         0.000000\n",
      "fed         0.000000\n",
      "febru       0.000000\n",
      "feb         0.000000\n",
      "fasc        0.000000\n",
      "famili      0.000000\n",
      "famy        0.000000\n",
      "fan         0.000000\n",
      "fantasy     0.000000\n",
      "faq         0.000000\n",
      "far         0.000000\n",
      "farm        0.000000\n",
      "fart        0.000000\n",
      "fash        0.000000\n",
      "feat        0.000000\n",
      "fast        0.000000\n",
      "fath        0.000000\n",
      "fault       0.000000\n",
      "fav         0.000000\n",
      "favo        0.000000\n",
      "favorit     0.000000\n",
      "fbi         0.000000\n",
      "fc          0.000000\n",
      "zon         0.000000\n",
      "\n",
      "[3000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "xgb = xgb.fit(features_CountVectorizer_train, y_train.toxic)\n",
    "imp = pd.DataFrame(xgb.feature_importances_,columns = ['Importance'],index = feature_names_CountVectorizer)\n",
    "imp = imp.sort_values(['Importance'], ascending = False)\n",
    "\n",
    "print(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 171)\n",
      "(153164, 171)\n",
      "The number of selected features is: 171\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(xgb, prefit=True,threshold = 0.0000001)\n",
    "features_CountVectorizer_train_new = model.transform(features_CountVectorizer_train)\n",
    "features_CountVectorizer_test_new = model.transform(features_CountVectorizer_test)\n",
    "# features_CountVectorizer_validate_new = model.transform(features_CountVectorizer_validate)\n",
    "print features_CountVectorizer_train_new.shape\n",
    "print features_CountVectorizer_test_new.shape\n",
    "# print features_CountVectorizer_validate_new.shape\n",
    "print \"The number of selected features is: %d\"%(features_CountVectorizer_train_new.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words features with the tf-idf algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 3000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 3000)\n",
    "features_TfidfVectorizer_train = vectorizer.fit_transform(X_train)\n",
    "# features_TfidfVectorizer_validate = vectorizer.transform(X_validate)\n",
    "features_TfidfVectorizer_test = vectorizer.transform(X_test)\n",
    "feature_names_TfidfVectorizer = vectorizer.get_feature_names()\n",
    "\n",
    "print features_TfidfVectorizer_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Importance\n",
      "fuck        0.193410\n",
      "suck        0.031519\n",
      "crap        0.028653\n",
      "artic       0.027221\n",
      "stupid      0.027221\n",
      "idiot       0.025788\n",
      "ass         0.022923\n",
      "gay         0.021490\n",
      "hel         0.020057\n",
      "shit        0.018625\n",
      "asshol      0.017192\n",
      "bullshit    0.017192\n",
      "hat         0.015759\n",
      "bitch       0.015759\n",
      "moron       0.015759\n",
      "cunt        0.014327\n",
      "faggot      0.014327\n",
      "pathet      0.014327\n",
      "los         0.012894\n",
      "liar        0.011461\n",
      "die         0.011461\n",
      "retard      0.011461\n",
      "dick        0.011461\n",
      "pen         0.011461\n",
      "jerk        0.011461\n",
      "piss        0.010029\n",
      "us          0.010029\n",
      "thank       0.010029\n",
      "shut        0.010029\n",
      "bastard     0.008596\n",
      "...              ...\n",
      "field       0.000000\n",
      "fif         0.000000\n",
      "fig         0.000000\n",
      "fight       0.000000\n",
      "fil         0.000000\n",
      "film        0.000000\n",
      "filt        0.000000\n",
      "feedback    0.000000\n",
      "fee         0.000000\n",
      "fed         0.000000\n",
      "fath        0.000000\n",
      "fantasy     0.000000\n",
      "faq         0.000000\n",
      "far         0.000000\n",
      "farm        0.000000\n",
      "fart        0.000000\n",
      "fasc        0.000000\n",
      "fash        0.000000\n",
      "fast        0.000000\n",
      "fault       0.000000\n",
      "febru       0.000000\n",
      "fav         0.000000\n",
      "favo        0.000000\n",
      "favorit     0.000000\n",
      "fbi         0.000000\n",
      "fc          0.000000\n",
      "fear        0.000000\n",
      "feat        0.000000\n",
      "feb         0.000000\n",
      "zon         0.000000\n",
      "\n",
      "[3000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "xgb = xgb.fit(features_TfidfVectorizer_train, y_train.toxic)\n",
    "imp = pd.DataFrame(xgb.feature_importances_,columns = ['Importance'],index = feature_names_TfidfVectorizer)\n",
    "imp = imp.sort_values(['Importance'], ascending = False)\n",
    "\n",
    "print(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 148)\n",
      "(153164, 148)\n",
      "The number of selected features is: 148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(xgb, prefit=True,threshold = 0.0000001)\n",
    "features_TfidfVectorizer_train_selected = model.transform(features_TfidfVectorizer_train)\n",
    "# features_TfidfVectorizer_validate_selected = model.transform(features_TfidfVectorizer_validate)\n",
    "features_TfidfVectorizer_test_selected = model.transform(features_TfidfVectorizer_test)\n",
    "print features_TfidfVectorizer_train_selected.shape\n",
    "# print features_TfidfVectorizer_validate_selected.shape\n",
    "print features_TfidfVectorizer_test_selected.shape\n",
    "print \"The number of selected features is: %d\"%(features_TfidfVectorizer_train_selected.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159557, 500)\n",
      "[12003, 26302, 38016, 44715, 45864, 85789, 89363, 91131, 99486, 115981, 120508, 135342, 148563, 155735]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "def tokenize(docs):\n",
    "    pattern = re.compile('[\\W_]+', re.UNICODE)\n",
    "    sentences = []\n",
    "    for d in docs:\n",
    "        sentence = d.lower().split(\" \")\n",
    "        sentence = [pattern.sub('', w) for w in sentence]\n",
    "        sentences.append( [w for w in sentence if w not in stopWords] )\n",
    "    return sentences\n",
    "\n",
    "def featurize_w2v(model, sentences):\n",
    "    f = np.zeros((len(sentences), model.vector_size))\n",
    "    for i,s in enumerate(sentences):\n",
    "        for w in s:\n",
    "            try:\n",
    "                vec = model[w]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            f[i,:] = f[i,:] + vec\n",
    "        f[i,:] = f[i,:] / len(s)\n",
    "    return f\n",
    "\n",
    "def delete_nans(features):\n",
    "    rows_to_delete = []\n",
    "    for i in range(len(features)):\n",
    "        if np.isnan(features[i].sum()):\n",
    "            rows_to_delete.append(i)\n",
    "    return rows_to_delete\n",
    "\n",
    "train_sentences = tokenize(X_train)\n",
    "model = Word2Vec(train_sentences, size=500, window=5, min_count=6, sample=1e-3, workers=2)\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "features_w2v_train = featurize_w2v(model, train_sentences)\n",
    "rows_to_delete_train = delete_nans(features_w2v_train)\n",
    "features_w2v_train = np.delete(features_w2v_train, rows_to_delete_train, 0)\n",
    "\n",
    "# validate_sentences = tokenize(X_validate)\n",
    "# features_w2v_validate = featurize_w2v(model, validate_sentences)\n",
    "# rows_to_delete_validate = delete_nans(features_w2v_validate)\n",
    "# features_w2v_validate = np.delete(features_w2v_validate, rows_to_delete_validate, 0)\n",
    "\n",
    "test_sentences = tokenize(X_test)\n",
    "features_w2v_test = featurize_w2v(model, test_sentences)\n",
    "rows_to_delete_test = delete_nans(features_w2v_test)\n",
    "features_w2v_test = np.delete(features_w2v_test, rows_to_delete_test, 0)\n",
    "\n",
    "print features_w2v_train.shape\n",
    "print rows_to_delete_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "n_folds = 3\n",
    "\n",
    "def cv(model, X_train, y_train):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train)\n",
    "    score = cross_val_score(model, X_train, y_train, scoring= 'roc_auc', cv = kf)\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Applications/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(max_features, output_dim=256))\n",
    "lstm_model.add(LSTM(60))\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 71631 samples, validate on 35281 samples\n",
      "Epoch 1/2\n",
      "71631/71631 [==============================] - 610s 9ms/step - loss: 0.0496 - acc: 0.9821 - val_loss: 0.0473 - val_acc: 0.9824\n",
      "Epoch 2/2\n",
      "71631/71631 [==============================] - 600s 8ms/step - loss: 0.0460 - acc: 0.9833 - val_loss: 0.0470 - val_acc: 0.9826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1329d7950>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_lstm, X_validate_lstm, y_train_lstm, y_validate_lstm = train_test_split(\n",
    "    feature_tokenizer_train, y_train, test_size=0.33, random_state=42)\n",
    "lstm_model.fit(X_train_lstm,y_train_lstm, batch_size=256, epochs=2, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9753588745307796\n"
     ]
    }
   ],
   "source": [
    "prediction_lstm = lstm_model.predict(X_validate_lstm)\n",
    "print roc_auc_score(y_validate_lstm.toxic, prediction_lstm[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# def build_model_svm(Tfid = False, svm_c = 0.1, svm_g = 0.005):\n",
    "#     svm_clf = svm.SVC(C = svm_c, gamma = svm_g,probability=True)\n",
    "#     if Tfid == 'Tfid':\n",
    "#         svm_clf.fit(features_TfidfVectorizer_train, y_train.toxic)\n",
    "#         pred = svm_clf.predict_proba(features_TfidfVectorizer_validate)\n",
    "#     elif Tfid == 'Counter':\n",
    "#         svm_clf.fit(features_CountVectorizer_train, y_train.toxic)\n",
    "#         pred = svm_clf.predict_proba(features_CountVectorizer_validate) \n",
    "#     else:\n",
    "#         svm_clf.fit(features_w2v_train, y_train[label].drop(y_train.index[rows_to_delete_train]))\n",
    "#         pred = svm_clf.predict_proba(features_w2v_validate)\n",
    "        \n",
    "#     return {\n",
    "#         \"Tfid\": Tfid,\n",
    "#         \"svm_c\": svm_c,\n",
    "#         \"svm_g\": svm_g,     \n",
    "#         \"auc\": roc_auc_score(y_validate.toxic, pred[:,1])\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from itertools import product\n",
    "# param_values = {\n",
    "#   \"svm_c\": [1, 2, 5, 10, 20],\n",
    "#     \"svm_g\": [0.05, 0.2, 0.5, 5, 50],\n",
    "#     \"Tfid\": [True, False]\n",
    "# }\n",
    "\n",
    "# results = []\n",
    "# max_auc = 0\n",
    "\n",
    "# for p in product(*param_values.values()):\n",
    "#     res = build_model_svm(**dict(zip(param_values.keys(), p)))\n",
    "#     results.append(res)\n",
    "#     if res.get('auc')>max_auc:\n",
    "#         max_auc = res.get('auc')\n",
    "#         Tfid_opt = res.get('Tfid')\n",
    "#         svm_c_opt = res.get('svm_c')\n",
    "#         svm_g_opt = res.get('svm_g')\n",
    "#     print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_rf(Tfid = 'Tfid',n_trees= 100):\n",
    "    rf_clf = RandomForestClassifier(n_estimators = n_trees)\n",
    "    if Tfid == 'Tfid':\n",
    "        score = cv(rf_clf, features_TfidfVectorizer_train, y_train.toxic)\n",
    "        return {\n",
    "            \"Tfid\": Tfid,\n",
    "            \"n_trees\": n_trees,\n",
    "            \"auc\":  np.mean(score)\n",
    "        }\n",
    "    elif Tfid == 'Counter':\n",
    "        score = cv(rf_clf, features_CountVectorizer_train, y_train.toxic)\n",
    "        return {\n",
    "            \"Tfid\": Tfid,\n",
    "            \"n_trees\": n_trees,\n",
    "            \"auc\":  np.mean(score)\n",
    "        }\n",
    "    else:\n",
    "        score = cv(rf_clf, features_w2v_train, y_train.toxic.drop(y_train.index[rows_to_delete_train]))\n",
    "        return {\n",
    "            \"Tfid\": Tfid,\n",
    "            \"n_trees\": n_trees,\n",
    "            \"auc\":  np.mean(score)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.900472221463993, 'Tfid': 'Word2Vec', 'n_trees': 10}\n",
      "{'auc': 0.932474776007839, 'Tfid': 'Word2Vec', 'n_trees': 50}\n",
      "{'auc': 0.9368080706899624, 'Tfid': 'Word2Vec', 'n_trees': 100}\n",
      "{'auc': 0.9390857666163148, 'Tfid': 'Word2Vec', 'n_trees': 200}\n",
      "{'auc': 0.9224602572278231, 'Tfid': 'Tfid', 'n_trees': 10}\n",
      "{'auc': 0.9479672713494175, 'Tfid': 'Tfid', 'n_trees': 50}\n",
      "{'auc': 0.9525974483053274, 'Tfid': 'Tfid', 'n_trees': 100}\n",
      "{'auc': 0.9539436649494664, 'Tfid': 'Tfid', 'n_trees': 200}\n",
      "{'auc': 0.9248396733731972, 'Tfid': 'Counter', 'n_trees': 10}\n",
      "{'auc': 0.9435143250272224, 'Tfid': 'Counter', 'n_trees': 50}\n",
      "{'auc': 0.9462083713513394, 'Tfid': 'Counter', 'n_trees': 100}\n",
      "{'auc': 0.9474485041968497, 'Tfid': 'Counter', 'n_trees': 200}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "param_values = {\n",
    "  \"Tfid\": ['Word2Vec','Tfid','Counter'],\n",
    "  \"n_trees\": [10, 50, 100, 200]\n",
    "}\n",
    "\n",
    "results = []\n",
    "max_auc = 0\n",
    "\n",
    "for p in product(*param_values.values()):\n",
    "    res = build_model_rf(**dict(zip(param_values.keys(), p)))\n",
    "    results.append(res)\n",
    "    if res.get('auc')>max_auc:\n",
    "        max_auc = res.get('auc')\n",
    "        Tfid_opt = res.get('Tfid')\n",
    "        n_trees_opt = res.get('n_trees')\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "def build_model(Tfid = 'Tfid',nb_alpha=1.0):\n",
    "    nb_clf = MultinomialNB(alpha=nb_alpha)\n",
    "    if Tfid == 'Tfid':\n",
    "        score = cv(nb_clf, features_TfidfVectorizer_train, y_train.toxic)\n",
    "    elif Tfid == 'Counter':\n",
    "        score = cv(nb_clf, features_CountVectorizer_train, y_train.toxic)\n",
    "    return {\n",
    "        \"Tfid\": Tfid,\n",
    "        \"nb_alpha\": nb_alpha,\n",
    "        \"auc\": np.mean(score)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb_alpha': 0.01, 'auc': 0.9506579353461703, 'Tfid': 'Tfid'}\n",
      "{'nb_alpha': 0.01, 'auc': 0.9209745849187193, 'Tfid': 'Counter'}\n",
      "{'nb_alpha': 0.1, 'auc': 0.9518184484871535, 'Tfid': 'Tfid'}\n",
      "{'nb_alpha': 0.1, 'auc': 0.9212816486662977, 'Tfid': 'Counter'}\n",
      "{'nb_alpha': 1.0, 'auc': 0.9544086196190392, 'Tfid': 'Tfid'}\n",
      "{'nb_alpha': 1.0, 'auc': 0.9221170163378615, 'Tfid': 'Counter'}\n",
      "{'nb_alpha': 2, 'auc': 0.9541552674449356, 'Tfid': 'Tfid'}\n",
      "{'nb_alpha': 2, 'auc': 0.9227563371912918, 'Tfid': 'Counter'}\n",
      "{'nb_alpha': 10, 'auc': 0.9377407998272237, 'Tfid': 'Tfid'}\n",
      "{'nb_alpha': 10, 'auc': 0.9234760607912956, 'Tfid': 'Counter'}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "param_values = {\n",
    "  \"Tfid\": ['Tfid','Counter'],\n",
    "  \"nb_alpha\": [0.01, 0.1, 1.0, 2,10]\n",
    "}\n",
    "\n",
    "results = []\n",
    "max_auc = 0\n",
    "\n",
    "for p in product(*param_values.values()):\n",
    "    res = build_model(**dict(zip(param_values.keys(), p)))\n",
    "    results.append(res)\n",
    "    if res.get('auc')>max_auc:\n",
    "        max_auc = res.get('auc')\n",
    "        Tfid_opt = res.get('Tfid')\n",
    "        nb_alpha_opt = res.get('nb_alpha')\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_lr(Tfid = 'Tfid',lr_c= 1):\n",
    "    lr_clf = LogisticRegression(C=lr_c, dual=False, n_jobs=1)\n",
    "    if Tfid == 'Tfid':\n",
    "        score = cv(lr_clf, features_TfidfVectorizer_train, y_train.toxic)\n",
    "        return {\n",
    "            \"Tfid\": Tfid,\n",
    "            \"lr_c\": lr_c,\n",
    "            \"auc\":  np.mean(score)\n",
    "        }\n",
    "    elif Tfid == 'Counter':\n",
    "        score = cv(lr_clf, features_CountVectorizer_train, y_train.toxic)\n",
    "        return {\n",
    "            \"Tfid\": Tfid,\n",
    "            \"lr_c\": lr_c,\n",
    "            \"auc\":  np.mean(score)\n",
    "        }\n",
    "    else:\n",
    "        score = cv(lr_clf, features_w2v_train, y_train.toxic.drop(y_train.index[rows_to_delete_train]))\n",
    "        return {\n",
    "            \"Tfid\": Tfid,\n",
    "            \"lr_c\": lr_c,\n",
    "            \"auc\":  np.mean(score)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr_c': 0.01, 'auc': 0.9402733356948132, 'Tfid': 'Tfid'}\n",
      "{'lr_c': 0.01, 'auc': 0.9422624459267811, 'Tfid': 'Counter'}\n",
      "{'lr_c': 0.01, 'auc': 0.9367029317189411, 'Tfid': 'Word2Vec'}\n",
      "{'lr_c': 0.1, 'auc': 0.9585442438457297, 'Tfid': 'Tfid'}\n",
      "{'lr_c': 0.1, 'auc': 0.9472235817634922, 'Tfid': 'Counter'}\n",
      "{'lr_c': 0.1, 'auc': 0.9498878721034272, 'Tfid': 'Word2Vec'}\n",
      "{'lr_c': 1.0, 'auc': 0.9653069476755065, 'Tfid': 'Tfid'}\n",
      "{'lr_c': 1.0, 'auc': 0.9472481236806066, 'Tfid': 'Counter'}\n",
      "{'lr_c': 1.0, 'auc': 0.9545608855556155, 'Tfid': 'Word2Vec'}\n",
      "{'lr_c': 2.0, 'auc': 0.9649358449275244, 'Tfid': 'Tfid'}\n",
      "{'lr_c': 2.0, 'auc': 0.9473891931486982, 'Tfid': 'Counter'}\n",
      "{'lr_c': 2.0, 'auc': 0.9549138455818168, 'Tfid': 'Word2Vec'}\n",
      "{'lr_c': 10.0, 'auc': 0.9618044230682744, 'Tfid': 'Tfid'}\n",
      "{'lr_c': 10.0, 'auc': 0.94727544114222, 'Tfid': 'Counter'}\n",
      "{'lr_c': 10.0, 'auc': 0.9553763416223734, 'Tfid': 'Word2Vec'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import product\n",
    "param_values = {\n",
    "  \"Tfid\": ['Tfid','Counter','Word2Vec'],\n",
    "  \"lr_c\": [0.01, 0.1, 1.0, 2.0 ,10.0]\n",
    "}\n",
    "\n",
    "results = []\n",
    "max_auc = 0\n",
    "\n",
    "for p in product(*param_values.values()):\n",
    "    res = build_model_lr(**dict(zip(param_values.keys(), p)))\n",
    "    results.append(res)\n",
    "    if res.get('auc')>max_auc:\n",
    "        max_auc = res.get('auc')\n",
    "        Tfid_opt = res.get('Tfid')\n",
    "        lr_c_opt = res.get('lr_c')\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB-LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from scipy import sparse\n",
    "\n",
    "class NbLRClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, C=1.0, dual=False, n_jobs=1):\n",
    "        self.C = C\n",
    "        self.dual = dual\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict(x.multiply(self._r))\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict_proba(x.multiply(self._r))\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # Check that X and y have correct shape\n",
    "        y = y.values\n",
    "        x, y = check_X_y(x, y, accept_sparse=True)\n",
    "\n",
    "        def pr(x, y_i, y):\n",
    "            p = x[y==y_i].sum(0)\n",
    "            return (p+1.1) / ((y==y_i).sum()+1)\n",
    "        self._r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))\n",
    "        x_nb = x.multiply(self._r)\n",
    "        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs).fit(x_nb, y)\n",
    "        return self\n",
    "    \n",
    "    def fit_w2v(self, x, y):\n",
    "        # Check that X and y have correct shape\n",
    "        y = y.values\n",
    "        x, y = check_X_y(x, y, accept_sparse=True)\n",
    "\n",
    "        def pr(x, y_i, y):\n",
    "            p = x[y==y_i].sum(0)\n",
    "            return (p+1.3) / ((y==y_i).sum()+1.3)\n",
    "        self._r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))\n",
    "        \n",
    "        x_nb = sparse.csr_matrix(x).multiply(self._r)\n",
    "        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs).fit(x_nb, y)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_nblr(Tfid = 'Tfid',lr_c= 1):\n",
    "    model = NbLRClassifier(C=lr_c, dual=False, n_jobs=-1)\n",
    "    if Tfid == 'Tfid':\n",
    "        score = cv(model, features_TfidfVectorizer_train, y_train.toxic)\n",
    "        return {\n",
    "            \"Tfid\": Tfid,\n",
    "            \"lr_c\": lr_c,\n",
    "            \"auc\":  np.mean(score)\n",
    "        }\n",
    "    elif Tfid == 'Counter':\n",
    "        score = cv(model, features_CountVectorizer_train, y_train.toxic)\n",
    "        return {\n",
    "            \"Tfid\": Tfid,\n",
    "            \"lr_c\": lr_c,\n",
    "            \"auc\":  np.mean(score)\n",
    "        }\n",
    "    else:\n",
    "        score = cv(model, features_w2v_train, y_train.toxic.drop(y_train.index[rows_to_delete_train]))\n",
    "        return {\n",
    "            \"Tfid\": Tfid,\n",
    "            \"lr_c\": lr_c,\n",
    "            \"auc\":  np.mean(score)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr_c': 0.01, 'auc': 0.9573069086982664, 'Tfid': 'Tfid'}\n",
      "{'lr_c': 0.01, 'auc': 0.9474459473514306, 'Tfid': 'Counter'}\n",
      "{'lr_c': 0.1, 'auc': 0.9632403776358842, 'Tfid': 'Tfid'}\n",
      "{'lr_c': 0.1, 'auc': 0.9480304962406572, 'Tfid': 'Counter'}\n",
      "{'lr_c': 1.0, 'auc': 0.9661523550097125, 'Tfid': 'Tfid'}\n",
      "{'lr_c': 1.0, 'auc': 0.947905421249103, 'Tfid': 'Counter'}\n",
      "{'lr_c': 2.0, 'auc': 0.9659902996819992, 'Tfid': 'Tfid'}\n",
      "{'lr_c': 2.0, 'auc': 0.9477916077995613, 'Tfid': 'Counter'}\n",
      "{'lr_c': 10.0, 'auc': 0.9641658774712377, 'Tfid': 'Tfid'}\n",
      "{'lr_c': 10.0, 'auc': 0.9477580550851467, 'Tfid': 'Counter'}\n"
     ]
    }
   ],
   "source": [
    "param_values = {\n",
    "  \"Tfid\": ['Tfid','Counter'],\n",
    "  \"lr_c\": [0.01, 0.1, 1.0, 2.0 ,10.0]\n",
    "}\n",
    "\n",
    "results = []\n",
    "max_auc = 0\n",
    "\n",
    "for p in product(*param_values.values()):\n",
    "    res = build_model_nblr(**dict(zip(param_values.keys(), p)))\n",
    "    results.append(res)\n",
    "    if res.get('auc')>max_auc:\n",
    "        max_auc = res.get('auc')\n",
    "        Tfid_opt = res.get('Tfid')\n",
    "        lr_c_opt = res.get('lr_c')\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Build and Predict in Testing Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 6)\n"
     ]
    }
   ],
   "source": [
    "preds_nblr = np.zeros((features_TfidfVectorizer_test.shape[0], len(list_classes)))\n",
    "nblr_model = NbLRClassifier(C=1, dual=False, n_jobs=-1)\n",
    "for i,label in enumerate(list_classes):\n",
    "    nblr_model.fit(features_TfidfVectorizer_train, y_train[label])\n",
    "    preds_nblr[:,i] = nblr_model.predict_proba(features_TfidfVectorizer_test)[:,1]\n",
    "print preds_nblr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.297667</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.050620</td>\n",
       "      <td>0.993505</td>\n",
       "      <td>0.578811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.005749</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.006962</td>\n",
       "      <td>0.001870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.008466</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.019654</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>0.000442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.999986      0.297667  0.999899  0.050620  0.993505   \n",
       "1  0000247867823ef7  0.005749      0.002184  0.002309  0.000537  0.006962   \n",
       "2  00013b17ad220c46  0.008466      0.000514  0.003402  0.000028  0.003644   \n",
       "3  00017563c3f7919a  0.001476      0.001068  0.001384  0.000511  0.002428   \n",
       "4  00017695ad8997eb  0.019654      0.001104  0.004853  0.000228  0.007441   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.578811  \n",
       "1       0.001870  \n",
       "2       0.000102  \n",
       "3       0.000252  \n",
       "4       0.000442  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = pd.read_csv('data/sample_submission.csv')\n",
    "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
    "submission = pd.concat([submid, pd.DataFrame(preds_nblr, columns = list_classes)], axis=1)\n",
    "submission.to_csv('submission_nblr.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NBLR testing score is 0.9727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 6)\n"
     ]
    }
   ],
   "source": [
    "preds_lr = np.zeros((features_TfidfVectorizer_test.shape[0], len(list_classes)))\n",
    "lr_model = lr_clf = LogisticRegression(C=1, dual=False, n_jobs=1)\n",
    "for i,label in enumerate(list_classes):\n",
    "    lr_model.fit(features_TfidfVectorizer_train, y_train[label])\n",
    "    preds_lr[:,i] = lr_model.predict_proba(features_TfidfVectorizer_test)[:,1]\n",
    "print preds_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999649</td>\n",
       "      <td>0.239714</td>\n",
       "      <td>0.998739</td>\n",
       "      <td>0.054813</td>\n",
       "      <td>0.984641</td>\n",
       "      <td>0.512128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.002291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.000684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.000759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.015524</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.001251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.999649      0.239714  0.998739  0.054813  0.984641   \n",
       "1  0000247867823ef7  0.009113      0.002605  0.004496  0.001958  0.007700   \n",
       "2  00013b17ad220c46  0.009903      0.001353  0.004375  0.000438  0.004377   \n",
       "3  00017563c3f7919a  0.003652      0.002097  0.003019  0.000897  0.003299   \n",
       "4  00017695ad8997eb  0.015524      0.001183  0.004439  0.000719  0.005861   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.512128  \n",
       "1       0.002291  \n",
       "2       0.000684  \n",
       "3       0.000759  \n",
       "4       0.001251  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
    "submission_lr = pd.concat([submid, pd.DataFrame(preds_lr, columns = list_classes)], axis=1)\n",
    "submission_lr.to_csv('submission_lr.csv', index=False)\n",
    "submission_lr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LR testing score is 0.9713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 6)\n"
     ]
    }
   ],
   "source": [
    "lstm_model.fit(feature_tokenizer_train,y_train, batch_size=256, epochs=2, validation_split=0.2,verbose=0)\n",
    "preds_lstm = lstm_model.predict(feature_tokenizer_test)\n",
    "print preds_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.993704</td>\n",
       "      <td>2.807285e-01</td>\n",
       "      <td>0.973476</td>\n",
       "      <td>4.038447e-02</td>\n",
       "      <td>0.889220</td>\n",
       "      <td>1.894136e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>3.071439e-06</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>7.989715e-06</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>1.016809e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.051714</td>\n",
       "      <td>2.639241e-04</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>3.494619e-04</td>\n",
       "      <td>0.008154</td>\n",
       "      <td>4.944871e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>5.036533e-08</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.315698e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.272676e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>1.278094e-05</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>3.120828e-05</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>4.616031e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene        threat    insult  \\\n",
       "0  00001cee341fdb12  0.993704  2.807285e-01  0.973476  4.038447e-02  0.889220   \n",
       "1  0000247867823ef7  0.000544  3.071439e-06  0.000101  7.989715e-06  0.000057   \n",
       "2  00013b17ad220c46  0.051714  2.639241e-04  0.005475  3.494619e-04  0.008154   \n",
       "3  00017563c3f7919a  0.000105  5.036533e-08  0.000018  1.315698e-07  0.000004   \n",
       "4  00017695ad8997eb  0.003982  1.278094e-05  0.000589  3.120828e-05  0.000408   \n",
       "\n",
       "   identity_hate  \n",
       "0   1.894136e-01  \n",
       "1   1.016809e-05  \n",
       "2   4.944871e-04  \n",
       "3   2.272676e-07  \n",
       "4   4.616031e-05  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
    "submission_lstm = pd.concat([submid, pd.DataFrame(preds_lstm, columns = list_classes)], axis=1)\n",
    "submission_lstm.to_csv('submission_lstm.csv', index=False)\n",
    "submission_lstm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM testing socre is 0.9764"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_avg = preds_lr*0.3 + preds_nblr*0.2 + preds_lstm*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.996744</td>\n",
       "      <td>0.271812</td>\n",
       "      <td>0.986340</td>\n",
       "      <td>0.046760</td>\n",
       "      <td>0.938703</td>\n",
       "      <td>0.364107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.030521</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.000473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.010579</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.000487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.996744      0.271812  0.986340  0.046760  0.938703   \n",
       "1  0000247867823ef7  0.004155      0.001220  0.001861  0.000699  0.003731   \n",
       "2  00013b17ad220c46  0.030521      0.000641  0.004731  0.000312  0.006119   \n",
       "3  00017563c3f7919a  0.001443      0.000843  0.001192  0.000371  0.001478   \n",
       "4  00017695ad8997eb  0.010579      0.000582  0.002597  0.000277  0.003451   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.364107  \n",
       "1       0.001066  \n",
       "2       0.000473  \n",
       "3       0.000278  \n",
       "4       0.000487  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
    "submission_lstm = pd.concat([submid, pd.DataFrame(pred_avg, columns = list_classes)], axis=1)\n",
    "submission_lstm.to_csv('submission_ensemble.csv', index=False)\n",
    "submission_lstm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score is 0.9796 after model ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
